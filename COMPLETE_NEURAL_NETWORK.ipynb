{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMPLETE_NEURAL_NETWORK.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOu51MyOy0u9RosqeQL5F/s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SUBHASH-KANDHWAY/MACHINE-LEARNING-PROJECTS/blob/master/COMPLETE_NEURAL_NETWORK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQs37rF-6UKZ"
      },
      "source": [
        "#ONE-HOT ENCODING\n",
        "# importing one hot encoder \n",
        "from sklearn from sklearn.preprocessing import OneHotEncoder\n",
        "# creating one hot encoder object \n",
        "onehotencoder = OneHotEncoder()\n",
        "#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object \n",
        "X = onehotencoder.fit_transform(data.Country.values.reshape(-1,1)).toarray()\n",
        "#To add this back into the original dataframe \n",
        "dfOneHot = pd.DataFrame(X, columns = [\"Country_\"+str(int(i)) for i in range(data.shape[1])]) \n",
        "df = pd.concat([data, dfOneHot], axis=1)\n",
        "#droping the country column \n",
        "df= df.drop(['Country'], axis=1) \n",
        "#printing to verify \n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR0f1G5J6oi-"
      },
      "source": [
        "#LABEL-ENCODING\n",
        "\n",
        "# Import label encoder \n",
        "from sklearn import preprocessing\n",
        "# label_encoder object knows how to understand word labels. \n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "# Encode labels in column 'Country'. \n",
        "data['Country']= label_encoder.fit_transform(data[â€˜Country']) \n",
        "print(data.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZaxs0Dv7WnS",
        "outputId": "963b790b-b833-4352-d4ef-030b66f0d065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "dataset=pd.read_csv('loan_data.csv')\n",
        "dataset.head(10)\n",
        "dataset.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(614, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAugLBw98Fl4",
        "outputId": "de167c85-11f0-4007-a025-29ecf33974d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loan_ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Married</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>Education</th>\n",
              "      <th>Self_Employed</th>\n",
              "      <th>ApplicantIncome</th>\n",
              "      <th>CoapplicantIncome</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>Loan_Amount_Term</th>\n",
              "      <th>Credit_History</th>\n",
              "      <th>Property_Area</th>\n",
              "      <th>Loan_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LP001002</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>5849</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LP001003</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>4583</td>\n",
              "      <td>1508.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Rural</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LP001005</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LP001006</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Not Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>2583</td>\n",
              "      <td>2358.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LP001008</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>6000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LP001011</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>5417</td>\n",
              "      <td>4196.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LP001013</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Not Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>2333</td>\n",
              "      <td>1516.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LP001014</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3+</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>3036</td>\n",
              "      <td>2504.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Semiurban</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LP001018</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>4006</td>\n",
              "      <td>1526.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LP001020</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>12841</td>\n",
              "      <td>10968.0</td>\n",
              "      <td>349.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Semiurban</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Loan_ID Gender Married  ... Credit_History Property_Area Loan_Status\n",
              "0  LP001002   Male      No  ...            1.0         Urban           Y\n",
              "1  LP001003   Male     Yes  ...            1.0         Rural           N\n",
              "2  LP001005   Male     Yes  ...            1.0         Urban           Y\n",
              "3  LP001006   Male     Yes  ...            1.0         Urban           Y\n",
              "4  LP001008   Male      No  ...            1.0         Urban           Y\n",
              "5  LP001011   Male     Yes  ...            1.0         Urban           Y\n",
              "6  LP001013   Male     Yes  ...            1.0         Urban           Y\n",
              "7  LP001014   Male     Yes  ...            0.0     Semiurban           N\n",
              "8  LP001018   Male     Yes  ...            1.0         Urban           Y\n",
              "9  LP001020   Male     Yes  ...            1.0     Semiurban           N\n",
              "\n",
              "[10 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olFN4H9Q8Z5l",
        "outputId": "24962fde-670b-40ff-ef0c-54b4b8feed14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "dataset.isnull().sum()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Loan_ID               0\n",
              "Gender               13\n",
              "Married               3\n",
              "Dependents           15\n",
              "Education             0\n",
              "Self_Employed        32\n",
              "ApplicantIncome       0\n",
              "CoapplicantIncome     0\n",
              "LoanAmount           22\n",
              "Loan_Amount_Term     14\n",
              "Credit_History       50\n",
              "Property_Area         0\n",
              "Loan_Status           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wayU9bVk8hJH",
        "outputId": "30c42975-33b2-4de9-b461-fd0d42c0a019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "dataset.dtypes"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Loan_ID               object\n",
              "Gender                object\n",
              "Married               object\n",
              "Dependents            object\n",
              "Education             object\n",
              "Self_Employed         object\n",
              "ApplicantIncome        int64\n",
              "CoapplicantIncome    float64\n",
              "LoanAmount           float64\n",
              "Loan_Amount_Term     float64\n",
              "Credit_History       float64\n",
              "Property_Area         object\n",
              "Loan_Status           object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEIfHmI48vkg"
      },
      "source": [
        "dataset['Gender'].fillna(dataset['Gender'].mode()[0],inplace=True)\n",
        "dataset['Married'].fillna(dataset['Married'].mode()[0],inplace=True)\n",
        "dataset['Dependents'].fillna(dataset['Dependents'].mode()[0],inplace=True)\n",
        "dataset['Education'].fillna(dataset['Education'].mode()[0],inplace=True)\n",
        "dataset['Self_Employed'].fillna(dataset['Self_Employed'].mode()[0],inplace=True)\n",
        "dataset['LoanAmount'].fillna(dataset['LoanAmount'].mean(), inplace=True)\n",
        "dataset['Loan_Amount_Term'].fillna(dataset['Loan_Amount_Term'].mode()[0], inplace=True)\n",
        "dataset['Credit_History'].fillna(dataset['Credit_History'].mode()[0], inplace=True)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJOI7Av4AX18",
        "outputId": "88e0b46b-73aa-42cf-cb55-2b4188b9199f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "dataset.isnull().sum()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Loan_ID              0\n",
              "Gender               0\n",
              "Married              0\n",
              "Dependents           0\n",
              "Education            0\n",
              "Self_Employed        0\n",
              "ApplicantIncome      0\n",
              "CoapplicantIncome    0\n",
              "LoanAmount           0\n",
              "Loan_Amount_Term     0\n",
              "Credit_History       0\n",
              "Property_Area        0\n",
              "Loan_Status          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDfl9MAGAqBQ"
      },
      "source": [
        "dataset['Gender']=dataset['Gender'].map({'Male':0,'Female':1})"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFp1FtoTBS7z"
      },
      "source": [
        "dataset['Married'] = dataset['Married'].map({'No': 0, 'Yes': 1})\n",
        "dataset['Dependents'] = dataset['Dependents'].map({'0': 0, '1': 1, '2': 2, '3+': 3})\n",
        "dataset['Education'] = dataset['Education'].map({'Graduate': 1, 'Not Graduate': 0})\n",
        "dataset['Self_Employed'] = dataset['Self_Employed'].map({'No': 0, 'Yes': 1})\n",
        "dataset['Property_Area'] = dataset['Property_Area'].map({'Rural': 0, 'Semiurban': 1, 'Urban': 2})\n",
        "dataset['Loan_Status'] = dataset['Loan_Status'].map({'N': 0, 'Y': 1})"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvu94v3hBztZ",
        "outputId": "05e29bce-0eaa-47ed-b189-95ad0827a702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loan_ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Married</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>Education</th>\n",
              "      <th>Self_Employed</th>\n",
              "      <th>ApplicantIncome</th>\n",
              "      <th>CoapplicantIncome</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>Loan_Amount_Term</th>\n",
              "      <th>Credit_History</th>\n",
              "      <th>Property_Area</th>\n",
              "      <th>Loan_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LP001002</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5849</td>\n",
              "      <td>0.0</td>\n",
              "      <td>146.412162</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LP001003</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4583</td>\n",
              "      <td>1508.0</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LP001005</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LP001006</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2583</td>\n",
              "      <td>2358.0</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LP001008</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LP001011</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5417</td>\n",
              "      <td>4196.0</td>\n",
              "      <td>267.000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LP001013</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2333</td>\n",
              "      <td>1516.0</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LP001014</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3036</td>\n",
              "      <td>2504.0</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LP001018</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4006</td>\n",
              "      <td>1526.0</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LP001020</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12841</td>\n",
              "      <td>10968.0</td>\n",
              "      <td>349.000000</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Loan_ID  Gender  Married  ...  Credit_History  Property_Area  Loan_Status\n",
              "0  LP001002       0        0  ...             1.0              2            1\n",
              "1  LP001003       0        1  ...             1.0              0            0\n",
              "2  LP001005       0        1  ...             1.0              2            1\n",
              "3  LP001006       0        1  ...             1.0              2            1\n",
              "4  LP001008       0        0  ...             1.0              2            1\n",
              "5  LP001011       0        1  ...             1.0              2            1\n",
              "6  LP001013       0        1  ...             1.0              2            1\n",
              "7  LP001014       0        1  ...             0.0              1            0\n",
              "8  LP001018       0        1  ...             1.0              2            1\n",
              "9  LP001020       0        1  ...             1.0              1            0\n",
              "\n",
              "[10 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUPnMsfpB9ae"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yme1un01CF18"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1Z7wN2BE8CDSYIJly5l0K9uqYdj9WUo3f'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDgAqTLYCIY9"
      },
      "source": [
        "# bringing variables in the range 0 to 1\n",
        "dataset['Dependents']=(dataset['Dependents']-dataset['Dependents'].min())/(dataset['Dependents'].max()-dataset['Dependents'].min())"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2dUxg_aCoSo"
      },
      "source": [
        "# applying for loop to bring all the variables in range 0 to 1\n",
        "\n",
        "for i in dataset.columns[1:]:\n",
        "    dataset[i] = (dataset[i] - dataset[i].min()) / (dataset[i].max() - dataset[i].min())"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC6ZGYDtC8db",
        "outputId": "bb5b0dee-884f-4260-f0ee-0be96a420507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "source": [
        "dataset.head(10)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loan_ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Married</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>Education</th>\n",
              "      <th>Self_Employed</th>\n",
              "      <th>ApplicantIncome</th>\n",
              "      <th>CoapplicantIncome</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>Loan_Amount_Term</th>\n",
              "      <th>Credit_History</th>\n",
              "      <th>Property_Area</th>\n",
              "      <th>Loan_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LP001002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.070489</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.198860</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LP001003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.054830</td>\n",
              "      <td>0.036192</td>\n",
              "      <td>0.172214</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LP001005</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.035250</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.082489</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LP001006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030093</td>\n",
              "      <td>0.056592</td>\n",
              "      <td>0.160637</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LP001008</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.072356</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191027</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LP001011</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.065145</td>\n",
              "      <td>0.100703</td>\n",
              "      <td>0.373372</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LP001013</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027001</td>\n",
              "      <td>0.036384</td>\n",
              "      <td>0.124457</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LP001014</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035696</td>\n",
              "      <td>0.060096</td>\n",
              "      <td>0.215630</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LP001018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.047693</td>\n",
              "      <td>0.036624</td>\n",
              "      <td>0.230101</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LP001020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.156970</td>\n",
              "      <td>0.263230</td>\n",
              "      <td>0.492041</td>\n",
              "      <td>0.74359</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Loan_ID  Gender  Married  ...  Credit_History  Property_Area  Loan_Status\n",
              "0  LP001002     0.0      0.0  ...             1.0            1.0          1.0\n",
              "1  LP001003     0.0      1.0  ...             1.0            0.0          0.0\n",
              "2  LP001005     0.0      1.0  ...             1.0            1.0          1.0\n",
              "3  LP001006     0.0      1.0  ...             1.0            1.0          1.0\n",
              "4  LP001008     0.0      0.0  ...             1.0            1.0          1.0\n",
              "5  LP001011     0.0      1.0  ...             1.0            1.0          1.0\n",
              "6  LP001013     0.0      1.0  ...             1.0            1.0          1.0\n",
              "7  LP001014     0.0      1.0  ...             0.0            0.5          0.0\n",
              "8  LP001018     0.0      1.0  ...             1.0            1.0          1.0\n",
              "9  LP001020     0.0      1.0  ...             1.0            0.5          0.0\n",
              "\n",
              "[10 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zup--yr3DI1H"
      },
      "source": [
        "dataset.to_csv('loan_prediction_data.csv', index=False)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxv1mOBoDNn_"
      },
      "source": [
        "# importing the required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeiiLsAjFdee"
      },
      "source": [
        "# loading the pre-processed dataset\n",
        "data = pd.read_csv('loan_prediction_data.csv')\n",
        "# removing the loan_ID since these are just the unique values\n",
        "data = data.drop('Loan_ID', axis=1)\n",
        "# separating the independent and dependent variables\n",
        "\n",
        "# storing all the independent variables as X\n",
        "x = data.drop('Loan_Status', axis=1)\n",
        "\n",
        "# storing the dependent variable as y\n",
        "y = data['Loan_Status']"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Zq7lnYF18j"
      },
      "source": [
        "# Creating training and validation set\n",
        "\n",
        "# stratify will make sure that the distribution of classes in train and validation set it similar\n",
        "# random state to regenerate the same train and validation set\n",
        "# test size 0.2 will keep 20% data in validation and remaining 80% in train set\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(x,y,stratify=data['Loan_Status'],random_state=10,test_size=0.2)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-at-roP6GMDN",
        "outputId": "b6c17bb6-be58-4055-ae66-267729c8d67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# checking the version of keras\n",
        "import keras\n",
        "print(keras.__version__)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WKzCzSMTUyi"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import InputLayer,Dense"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H92QTN2PY-0v",
        "outputId": "c7c81686-1b24-4b07-ea1d-820a450d4b8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(491, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vp-GzxJZS-n",
        "outputId": "55fc2a02-4ee3-480a-ff8e-6c220dcb57d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape[1]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QURGYJFZdy4"
      },
      "source": [
        "input_neuron=X_train.shape[1]\n",
        "output_neurons = 1"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRi_tYjNbJdl"
      },
      "source": [
        "### a. Create a model\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1iZNZ3kwSHRNf-Irn3DZmMuBb6K-Lro7w'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xR6Vvh8bRRA"
      },
      "source": [
        "### b. Defining different layers\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=16X6De2hua1XJBe3dfmUUeGTgP6PbXEpc'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyvbs4xTbLJT"
      },
      "source": [
        "hidden1_neuron=10\n",
        "hidden2_neuron=5\n",
        "hidden=2"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLuYmZaxbvPE"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(input_neuron,)))\n",
        "model.add(Dense(units=hidden1_neuron,activation='relu'))\n",
        "model.add(Dense(units=hidden2_neuron,activation='relu'))\n",
        "model.add(Dense(units=output_neurons,activation='sigmoid'))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI4k_tIQdlS1",
        "outputId": "caa546ab-9f85-4d8b-c6eb-ff0fedf4b708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                120       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 55        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 181\n",
            "Trainable params: 181\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQEOBpa2drXF",
        "outputId": "f32f99cf-50a3-4494-fd7c-8db34a6eafb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of parameters between input and first hidden layer\n",
        "\n",
        "input_neuron*hidden1_neuron"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "110"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAPkyx00d93H",
        "outputId": "df5424ae-4f8e-46f0-fb7b-ff5e1c92f95f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of parameters between input and first hidden layer\n",
        "\n",
        "# adding the bias for each neuron of first hidden layer\n",
        "\n",
        "input_neuron*hidden1_neuron + 10"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRfN-oULeLcH",
        "outputId": "e17d6750-de45-45b6-90e6-dcf95ab1e036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of parameters between first and second hidden layer\n",
        "\n",
        "# number of parameters between first and second hidden layer\n",
        "\n",
        "hidden2_neuron*hidden1_neuron + 5"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElIDm1kref2u"
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vc0Fo6We-LP",
        "outputId": "2b9f5ac7-2ef8-48b8-be94-e77a636468dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# training the model\n",
        "\n",
        "# passing the independent and dependent features for training set for training the model\n",
        "\n",
        "# validation data will be evaluated at the end of each epoch\n",
        "\n",
        "# setting the epochs as 50\n",
        "\n",
        "# storing the trained model in model_history variable which will be used to visualize the training process\n",
        "\n",
        "model_history=model.fit(X_train, y_train,validation_data=(X_test, y_test),batch_size=64,epochs=500)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3903 - accuracy: 0.8411 - val_loss: 0.5653 - val_accuracy: 0.7805\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8411 - val_loss: 0.5665 - val_accuracy: 0.7805\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8432 - val_loss: 0.5668 - val_accuracy: 0.7724\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.8411 - val_loss: 0.5678 - val_accuracy: 0.7724\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8411 - val_loss: 0.5662 - val_accuracy: 0.7805\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8452 - val_loss: 0.5673 - val_accuracy: 0.7724\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8411 - val_loss: 0.5674 - val_accuracy: 0.7724\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8411 - val_loss: 0.5675 - val_accuracy: 0.7724\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8411 - val_loss: 0.5669 - val_accuracy: 0.7805\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.8391 - val_loss: 0.5671 - val_accuracy: 0.7805\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.8411 - val_loss: 0.5694 - val_accuracy: 0.7642\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8411 - val_loss: 0.5673 - val_accuracy: 0.7724\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8432 - val_loss: 0.5670 - val_accuracy: 0.7805\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8391 - val_loss: 0.5670 - val_accuracy: 0.7724\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8432 - val_loss: 0.5675 - val_accuracy: 0.7724\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8411 - val_loss: 0.5680 - val_accuracy: 0.7724\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8391 - val_loss: 0.5674 - val_accuracy: 0.7805\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8411 - val_loss: 0.5689 - val_accuracy: 0.7724\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8411 - val_loss: 0.5691 - val_accuracy: 0.7724\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8411 - val_loss: 0.5689 - val_accuracy: 0.7724\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8411 - val_loss: 0.5678 - val_accuracy: 0.7886\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8391 - val_loss: 0.5698 - val_accuracy: 0.7724\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8411 - val_loss: 0.5701 - val_accuracy: 0.7724\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8411 - val_loss: 0.5695 - val_accuracy: 0.7724\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8432 - val_loss: 0.5688 - val_accuracy: 0.7724\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8411 - val_loss: 0.5694 - val_accuracy: 0.7724\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8411 - val_loss: 0.5697 - val_accuracy: 0.7642\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8411 - val_loss: 0.5685 - val_accuracy: 0.7724\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8432 - val_loss: 0.5672 - val_accuracy: 0.7805\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.8411 - val_loss: 0.5683 - val_accuracy: 0.7724\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8411 - val_loss: 0.5690 - val_accuracy: 0.7724\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8411 - val_loss: 0.5685 - val_accuracy: 0.7724\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8411 - val_loss: 0.5698 - val_accuracy: 0.7724\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8411 - val_loss: 0.5702 - val_accuracy: 0.7724\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8391 - val_loss: 0.5695 - val_accuracy: 0.7805\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8411 - val_loss: 0.5693 - val_accuracy: 0.7805\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.8411 - val_loss: 0.5704 - val_accuracy: 0.7724\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8411 - val_loss: 0.5696 - val_accuracy: 0.7724\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8391 - val_loss: 0.5694 - val_accuracy: 0.7724\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8411 - val_loss: 0.5690 - val_accuracy: 0.7724\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8432 - val_loss: 0.5694 - val_accuracy: 0.7724\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8411 - val_loss: 0.5692 - val_accuracy: 0.7724\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8411 - val_loss: 0.5696 - val_accuracy: 0.7724\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8411 - val_loss: 0.5705 - val_accuracy: 0.7724\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8411 - val_loss: 0.5697 - val_accuracy: 0.7724\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8411 - val_loss: 0.5695 - val_accuracy: 0.7724\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8411 - val_loss: 0.5699 - val_accuracy: 0.7724\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8411 - val_loss: 0.5698 - val_accuracy: 0.7724\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8411 - val_loss: 0.5703 - val_accuracy: 0.7724\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8350 - val_loss: 0.5692 - val_accuracy: 0.7805\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8391 - val_loss: 0.5705 - val_accuracy: 0.7724\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3896 - accuracy: 0.8391 - val_loss: 0.5730 - val_accuracy: 0.7642\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8411 - val_loss: 0.5695 - val_accuracy: 0.7805\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8411 - val_loss: 0.5695 - val_accuracy: 0.7805\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8391 - val_loss: 0.5714 - val_accuracy: 0.7642\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8391 - val_loss: 0.5720 - val_accuracy: 0.7724\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8411 - val_loss: 0.5706 - val_accuracy: 0.7724\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8411 - val_loss: 0.5705 - val_accuracy: 0.7724\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8432 - val_loss: 0.5707 - val_accuracy: 0.7724\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8411 - val_loss: 0.5732 - val_accuracy: 0.7642\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8411 - val_loss: 0.5712 - val_accuracy: 0.7724\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8391 - val_loss: 0.5709 - val_accuracy: 0.7724\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8411 - val_loss: 0.5722 - val_accuracy: 0.7724\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8411 - val_loss: 0.5724 - val_accuracy: 0.7724\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8411 - val_loss: 0.5719 - val_accuracy: 0.7724\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8371 - val_loss: 0.5713 - val_accuracy: 0.7805\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8371 - val_loss: 0.5714 - val_accuracy: 0.7724\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8411 - val_loss: 0.5717 - val_accuracy: 0.7642\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8411 - val_loss: 0.5708 - val_accuracy: 0.7805\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3884 - accuracy: 0.8411 - val_loss: 0.5725 - val_accuracy: 0.7724\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8411 - val_loss: 0.5724 - val_accuracy: 0.7724\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8411 - val_loss: 0.5724 - val_accuracy: 0.7724\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8411 - val_loss: 0.5727 - val_accuracy: 0.7642\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8371 - val_loss: 0.5714 - val_accuracy: 0.7805\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8432 - val_loss: 0.5727 - val_accuracy: 0.7724\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8391 - val_loss: 0.5726 - val_accuracy: 0.7724\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8391 - val_loss: 0.5742 - val_accuracy: 0.7642\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8432 - val_loss: 0.5709 - val_accuracy: 0.7805\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8432 - val_loss: 0.5709 - val_accuracy: 0.7805\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8411 - val_loss: 0.5739 - val_accuracy: 0.7642\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8411 - val_loss: 0.5718 - val_accuracy: 0.7724\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8391 - val_loss: 0.5709 - val_accuracy: 0.7805\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8432 - val_loss: 0.5734 - val_accuracy: 0.7724\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8411 - val_loss: 0.5740 - val_accuracy: 0.7724\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8411 - val_loss: 0.5718 - val_accuracy: 0.7805\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.8432 - val_loss: 0.5740 - val_accuracy: 0.7724\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8411 - val_loss: 0.5725 - val_accuracy: 0.7724\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8411 - val_loss: 0.5739 - val_accuracy: 0.7724\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8411 - val_loss: 0.5737 - val_accuracy: 0.7724\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8371 - val_loss: 0.5724 - val_accuracy: 0.7805\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8371 - val_loss: 0.5732 - val_accuracy: 0.7724\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8411 - val_loss: 0.5725 - val_accuracy: 0.7724\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8432 - val_loss: 0.5725 - val_accuracy: 0.7724\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8411 - val_loss: 0.5724 - val_accuracy: 0.7805\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3873 - accuracy: 0.8411 - val_loss: 0.5737 - val_accuracy: 0.7724\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8411 - val_loss: 0.5750 - val_accuracy: 0.7724\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8371 - val_loss: 0.5730 - val_accuracy: 0.7805\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3884 - accuracy: 0.8371 - val_loss: 0.5733 - val_accuracy: 0.7805\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8391 - val_loss: 0.5749 - val_accuracy: 0.7642\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8411 - val_loss: 0.5735 - val_accuracy: 0.7724\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8411 - val_loss: 0.5726 - val_accuracy: 0.7805\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8432 - val_loss: 0.5744 - val_accuracy: 0.7724\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8411 - val_loss: 0.5744 - val_accuracy: 0.7642\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8391 - val_loss: 0.5732 - val_accuracy: 0.7724\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8371 - val_loss: 0.5736 - val_accuracy: 0.7805\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8411 - val_loss: 0.5759 - val_accuracy: 0.7724\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8411 - val_loss: 0.5737 - val_accuracy: 0.7805\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8411 - val_loss: 0.5746 - val_accuracy: 0.7724\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8432 - val_loss: 0.5744 - val_accuracy: 0.7805\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8391 - val_loss: 0.5738 - val_accuracy: 0.7805\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8432 - val_loss: 0.5756 - val_accuracy: 0.7724\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8391 - val_loss: 0.5773 - val_accuracy: 0.7642\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8411 - val_loss: 0.5750 - val_accuracy: 0.7724\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8391 - val_loss: 0.5739 - val_accuracy: 0.7805\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8432 - val_loss: 0.5759 - val_accuracy: 0.7724\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8432 - val_loss: 0.5755 - val_accuracy: 0.7724\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8411 - val_loss: 0.5752 - val_accuracy: 0.7724\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8391 - val_loss: 0.5742 - val_accuracy: 0.7886\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8371 - val_loss: 0.5748 - val_accuracy: 0.7805\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8391 - val_loss: 0.5758 - val_accuracy: 0.7724\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8391 - val_loss: 0.5756 - val_accuracy: 0.7724\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8391 - val_loss: 0.5744 - val_accuracy: 0.7805\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3869 - accuracy: 0.8391 - val_loss: 0.5763 - val_accuracy: 0.7724\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8391 - val_loss: 0.5781 - val_accuracy: 0.7642\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8411 - val_loss: 0.5762 - val_accuracy: 0.7724\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8432 - val_loss: 0.5767 - val_accuracy: 0.7724\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8371 - val_loss: 0.5756 - val_accuracy: 0.7805\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8371 - val_loss: 0.5750 - val_accuracy: 0.7805\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3873 - accuracy: 0.8411 - val_loss: 0.5780 - val_accuracy: 0.7642\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8432 - val_loss: 0.5750 - val_accuracy: 0.7805\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8411 - val_loss: 0.5763 - val_accuracy: 0.7724\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8411 - val_loss: 0.5757 - val_accuracy: 0.7724\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8411 - val_loss: 0.5774 - val_accuracy: 0.7724\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8391 - val_loss: 0.5760 - val_accuracy: 0.7805\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8432 - val_loss: 0.5769 - val_accuracy: 0.7724\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8432 - val_loss: 0.5772 - val_accuracy: 0.7724\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8411 - val_loss: 0.5771 - val_accuracy: 0.7805\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8452 - val_loss: 0.5796 - val_accuracy: 0.7642\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8473 - val_loss: 0.5780 - val_accuracy: 0.7724\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8411 - val_loss: 0.5760 - val_accuracy: 0.7805\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8391 - val_loss: 0.5783 - val_accuracy: 0.7724\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8411 - val_loss: 0.5794 - val_accuracy: 0.7642\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8391 - val_loss: 0.5764 - val_accuracy: 0.7805\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8411 - val_loss: 0.5773 - val_accuracy: 0.7724\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8432 - val_loss: 0.5785 - val_accuracy: 0.7724\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8432 - val_loss: 0.5778 - val_accuracy: 0.7724\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3873 - accuracy: 0.8391 - val_loss: 0.5765 - val_accuracy: 0.7805\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8432 - val_loss: 0.5784 - val_accuracy: 0.7724\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3869 - accuracy: 0.8452 - val_loss: 0.5774 - val_accuracy: 0.7724\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8452 - val_loss: 0.5774 - val_accuracy: 0.7724\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8432 - val_loss: 0.5765 - val_accuracy: 0.7805\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8432 - val_loss: 0.5782 - val_accuracy: 0.7724\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8432 - val_loss: 0.5779 - val_accuracy: 0.7724\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8432 - val_loss: 0.5790 - val_accuracy: 0.7724\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8411 - val_loss: 0.5771 - val_accuracy: 0.7724\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8411 - val_loss: 0.5780 - val_accuracy: 0.7724\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8432 - val_loss: 0.5791 - val_accuracy: 0.7642\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8411 - val_loss: 0.5789 - val_accuracy: 0.7724\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8432 - val_loss: 0.5784 - val_accuracy: 0.7805\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8391 - val_loss: 0.5786 - val_accuracy: 0.7724\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8411 - val_loss: 0.5802 - val_accuracy: 0.7642\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8391 - val_loss: 0.5790 - val_accuracy: 0.7724\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8391 - val_loss: 0.5790 - val_accuracy: 0.7724\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8432 - val_loss: 0.5808 - val_accuracy: 0.7642\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8452 - val_loss: 0.5789 - val_accuracy: 0.7724\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8432 - val_loss: 0.5800 - val_accuracy: 0.7642\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8411 - val_loss: 0.5792 - val_accuracy: 0.7724\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8432 - val_loss: 0.5801 - val_accuracy: 0.7724\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8432 - val_loss: 0.5798 - val_accuracy: 0.7724\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8473 - val_loss: 0.5797 - val_accuracy: 0.7724\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8432 - val_loss: 0.5798 - val_accuracy: 0.7724\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8411 - val_loss: 0.5784 - val_accuracy: 0.7724\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8391 - val_loss: 0.5791 - val_accuracy: 0.7724\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8432 - val_loss: 0.5790 - val_accuracy: 0.7724\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8411 - val_loss: 0.5785 - val_accuracy: 0.7724\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8452 - val_loss: 0.5810 - val_accuracy: 0.7642\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8432 - val_loss: 0.5800 - val_accuracy: 0.7724\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8391 - val_loss: 0.5802 - val_accuracy: 0.7724\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8473 - val_loss: 0.5838 - val_accuracy: 0.7642\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8391 - val_loss: 0.5818 - val_accuracy: 0.7642\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8371 - val_loss: 0.5791 - val_accuracy: 0.7805\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8432 - val_loss: 0.5819 - val_accuracy: 0.7642\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8452 - val_loss: 0.5798 - val_accuracy: 0.7724\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8411 - val_loss: 0.5799 - val_accuracy: 0.7724\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8452 - val_loss: 0.5815 - val_accuracy: 0.7724\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8432 - val_loss: 0.5799 - val_accuracy: 0.7724\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8432 - val_loss: 0.5816 - val_accuracy: 0.7642\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8452 - val_loss: 0.5796 - val_accuracy: 0.7724\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8411 - val_loss: 0.5805 - val_accuracy: 0.7724\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8411 - val_loss: 0.5803 - val_accuracy: 0.7724\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8411 - val_loss: 0.5819 - val_accuracy: 0.7642\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8452 - val_loss: 0.5801 - val_accuracy: 0.7805\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8411 - val_loss: 0.5793 - val_accuracy: 0.7805\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8432 - val_loss: 0.5830 - val_accuracy: 0.7642\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8432 - val_loss: 0.5836 - val_accuracy: 0.7642\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.8452 - val_loss: 0.5811 - val_accuracy: 0.7724\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8411 - val_loss: 0.5823 - val_accuracy: 0.7724\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8473 - val_loss: 0.5834 - val_accuracy: 0.7642\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8432 - val_loss: 0.5814 - val_accuracy: 0.7724\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8411 - val_loss: 0.5825 - val_accuracy: 0.7724\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3873 - accuracy: 0.8452 - val_loss: 0.5852 - val_accuracy: 0.7642\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8411 - val_loss: 0.5809 - val_accuracy: 0.7805\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8350 - val_loss: 0.5812 - val_accuracy: 0.7805\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8432 - val_loss: 0.5862 - val_accuracy: 0.7642\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8411 - val_loss: 0.5844 - val_accuracy: 0.7724\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8473 - val_loss: 0.5823 - val_accuracy: 0.7805\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8473 - val_loss: 0.5845 - val_accuracy: 0.7724\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8473 - val_loss: 0.5833 - val_accuracy: 0.7724\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8473 - val_loss: 0.5844 - val_accuracy: 0.7724\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3850 - accuracy: 0.8473 - val_loss: 0.5835 - val_accuracy: 0.7724\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3850 - accuracy: 0.8452 - val_loss: 0.5832 - val_accuracy: 0.7724\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8473 - val_loss: 0.5850 - val_accuracy: 0.7724\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8411 - val_loss: 0.5827 - val_accuracy: 0.7805\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8473 - val_loss: 0.5837 - val_accuracy: 0.7724\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8473 - val_loss: 0.5860 - val_accuracy: 0.7724\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8452 - val_loss: 0.5846 - val_accuracy: 0.7724\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8350 - val_loss: 0.5834 - val_accuracy: 0.7805\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8452 - val_loss: 0.5851 - val_accuracy: 0.7724\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8452 - val_loss: 0.5875 - val_accuracy: 0.7642\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8432 - val_loss: 0.5843 - val_accuracy: 0.7724\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.8411 - val_loss: 0.5839 - val_accuracy: 0.7805\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8432 - val_loss: 0.5856 - val_accuracy: 0.7724\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8452 - val_loss: 0.5865 - val_accuracy: 0.7724\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8473 - val_loss: 0.5858 - val_accuracy: 0.7724\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8452 - val_loss: 0.5855 - val_accuracy: 0.7724\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3850 - accuracy: 0.8452 - val_loss: 0.5852 - val_accuracy: 0.7805\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8452 - val_loss: 0.5867 - val_accuracy: 0.7724\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8473 - val_loss: 0.5859 - val_accuracy: 0.7724\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.8432 - val_loss: 0.5856 - val_accuracy: 0.7724\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8473 - val_loss: 0.5859 - val_accuracy: 0.7724\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8473 - val_loss: 0.5867 - val_accuracy: 0.7724\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.8473 - val_loss: 0.5873 - val_accuracy: 0.7724\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8432 - val_loss: 0.5857 - val_accuracy: 0.7724\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3849 - accuracy: 0.8473 - val_loss: 0.5880 - val_accuracy: 0.7724\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.8473 - val_loss: 0.5865 - val_accuracy: 0.7724\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8473 - val_loss: 0.5862 - val_accuracy: 0.7724\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8473 - val_loss: 0.5880 - val_accuracy: 0.7724\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3849 - accuracy: 0.8473 - val_loss: 0.5862 - val_accuracy: 0.7724\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3850 - accuracy: 0.8452 - val_loss: 0.5857 - val_accuracy: 0.7724\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8473 - val_loss: 0.5875 - val_accuracy: 0.7724\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8473 - val_loss: 0.5886 - val_accuracy: 0.7724\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8473 - val_loss: 0.5891 - val_accuracy: 0.7642\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8452 - val_loss: 0.5876 - val_accuracy: 0.7724\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8473 - val_loss: 0.5884 - val_accuracy: 0.7724\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3841 - accuracy: 0.8473 - val_loss: 0.5881 - val_accuracy: 0.7724\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3842 - accuracy: 0.8473 - val_loss: 0.5872 - val_accuracy: 0.7724\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3842 - accuracy: 0.8473 - val_loss: 0.5885 - val_accuracy: 0.7724\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8411 - val_loss: 0.5869 - val_accuracy: 0.7724\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8493 - val_loss: 0.5912 - val_accuracy: 0.7561\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8493 - val_loss: 0.5884 - val_accuracy: 0.7724\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8452 - val_loss: 0.5866 - val_accuracy: 0.7805\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8391 - val_loss: 0.5870 - val_accuracy: 0.7805\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8493 - val_loss: 0.5889 - val_accuracy: 0.7724\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.8493 - val_loss: 0.5872 - val_accuracy: 0.7724\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8432 - val_loss: 0.5871 - val_accuracy: 0.7724\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8473 - val_loss: 0.5915 - val_accuracy: 0.7642\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8473 - val_loss: 0.5899 - val_accuracy: 0.7724\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8452 - val_loss: 0.5880 - val_accuracy: 0.7724\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8473 - val_loss: 0.5900 - val_accuracy: 0.7724\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8473 - val_loss: 0.5890 - val_accuracy: 0.7724\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.8473 - val_loss: 0.5888 - val_accuracy: 0.7724\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8452 - val_loss: 0.5891 - val_accuracy: 0.7724\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3840 - accuracy: 0.8452 - val_loss: 0.5888 - val_accuracy: 0.7724\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8473 - val_loss: 0.5908 - val_accuracy: 0.7642\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8452 - val_loss: 0.5885 - val_accuracy: 0.7724\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3841 - accuracy: 0.8432 - val_loss: 0.5884 - val_accuracy: 0.7724\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8452 - val_loss: 0.5896 - val_accuracy: 0.7724\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.8452 - val_loss: 0.5900 - val_accuracy: 0.7724\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8493 - val_loss: 0.5885 - val_accuracy: 0.7724\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3850 - accuracy: 0.8432 - val_loss: 0.5871 - val_accuracy: 0.7805\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8473 - val_loss: 0.5882 - val_accuracy: 0.7724\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8513 - val_loss: 0.5915 - val_accuracy: 0.7642\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8493 - val_loss: 0.5882 - val_accuracy: 0.7724\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8411 - val_loss: 0.5871 - val_accuracy: 0.7805\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8432 - val_loss: 0.5898 - val_accuracy: 0.7724\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8473 - val_loss: 0.5889 - val_accuracy: 0.7724\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8473 - val_loss: 0.5893 - val_accuracy: 0.7724\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8452 - val_loss: 0.5891 - val_accuracy: 0.7724\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8432 - val_loss: 0.5923 - val_accuracy: 0.7642\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8391 - val_loss: 0.5886 - val_accuracy: 0.7805\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8452 - val_loss: 0.5904 - val_accuracy: 0.7724\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8452 - val_loss: 0.5906 - val_accuracy: 0.7724\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8452 - val_loss: 0.5885 - val_accuracy: 0.7805\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8432 - val_loss: 0.5887 - val_accuracy: 0.7805\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.8513 - val_loss: 0.5913 - val_accuracy: 0.7642\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3841 - accuracy: 0.8452 - val_loss: 0.5904 - val_accuracy: 0.7724\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.8513 - val_loss: 0.5902 - val_accuracy: 0.7724\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.8432 - val_loss: 0.5895 - val_accuracy: 0.7805\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8432 - val_loss: 0.5898 - val_accuracy: 0.7724\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.8473 - val_loss: 0.5916 - val_accuracy: 0.7724\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8473 - val_loss: 0.5917 - val_accuracy: 0.7642\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3850 - accuracy: 0.8452 - val_loss: 0.5901 - val_accuracy: 0.7724\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.8452 - val_loss: 0.5924 - val_accuracy: 0.7724\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8452 - val_loss: 0.5909 - val_accuracy: 0.7724\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8473 - val_loss: 0.5919 - val_accuracy: 0.7724\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3841 - accuracy: 0.8493 - val_loss: 0.5914 - val_accuracy: 0.7724\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.8452 - val_loss: 0.5900 - val_accuracy: 0.7805\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8452 - val_loss: 0.5917 - val_accuracy: 0.7642\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3830 - accuracy: 0.8473 - val_loss: 0.5906 - val_accuracy: 0.7805\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8513 - val_loss: 0.5901 - val_accuracy: 0.7805\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8452 - val_loss: 0.5919 - val_accuracy: 0.7724\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8473 - val_loss: 0.5915 - val_accuracy: 0.7724\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.8473 - val_loss: 0.5907 - val_accuracy: 0.7724\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3828 - accuracy: 0.8473 - val_loss: 0.5910 - val_accuracy: 0.7724\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.8473 - val_loss: 0.5916 - val_accuracy: 0.7724\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3830 - accuracy: 0.8452 - val_loss: 0.5916 - val_accuracy: 0.7724\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3828 - accuracy: 0.8452 - val_loss: 0.5925 - val_accuracy: 0.7724\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8452 - val_loss: 0.5914 - val_accuracy: 0.7724\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8452 - val_loss: 0.5918 - val_accuracy: 0.7724\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8473 - val_loss: 0.5925 - val_accuracy: 0.7642\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8513 - val_loss: 0.5933 - val_accuracy: 0.7642\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8493 - val_loss: 0.5903 - val_accuracy: 0.7805\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8473 - val_loss: 0.5909 - val_accuracy: 0.7724\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8452 - val_loss: 0.5913 - val_accuracy: 0.7724\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8452 - val_loss: 0.5916 - val_accuracy: 0.7642\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.8473 - val_loss: 0.5921 - val_accuracy: 0.7642\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3822 - accuracy: 0.8473 - val_loss: 0.5906 - val_accuracy: 0.7805\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3830 - accuracy: 0.8493 - val_loss: 0.5914 - val_accuracy: 0.7805\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8473 - val_loss: 0.5932 - val_accuracy: 0.7642\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8473 - val_loss: 0.5917 - val_accuracy: 0.7724\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3828 - accuracy: 0.8493 - val_loss: 0.5933 - val_accuracy: 0.7642\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8452 - val_loss: 0.5918 - val_accuracy: 0.7805\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8452 - val_loss: 0.5926 - val_accuracy: 0.7724\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3828 - accuracy: 0.8432 - val_loss: 0.5916 - val_accuracy: 0.7805\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8452 - val_loss: 0.5925 - val_accuracy: 0.7724\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8493 - val_loss: 0.5924 - val_accuracy: 0.7805\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3829 - accuracy: 0.8452 - val_loss: 0.5918 - val_accuracy: 0.7805\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8473 - val_loss: 0.5941 - val_accuracy: 0.7642\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8452 - val_loss: 0.5918 - val_accuracy: 0.7724\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3822 - accuracy: 0.8452 - val_loss: 0.5929 - val_accuracy: 0.7724\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3830 - accuracy: 0.8493 - val_loss: 0.5951 - val_accuracy: 0.7642\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8473 - val_loss: 0.5925 - val_accuracy: 0.7724\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3821 - accuracy: 0.8493 - val_loss: 0.5916 - val_accuracy: 0.7805\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.8493 - val_loss: 0.5923 - val_accuracy: 0.7724\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8473 - val_loss: 0.5924 - val_accuracy: 0.7724\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.8473 - val_loss: 0.5931 - val_accuracy: 0.7642\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8513 - val_loss: 0.5931 - val_accuracy: 0.7724\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8473 - val_loss: 0.5925 - val_accuracy: 0.7724\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8493 - val_loss: 0.5941 - val_accuracy: 0.7642\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8493 - val_loss: 0.5932 - val_accuracy: 0.7724\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.8452 - val_loss: 0.5928 - val_accuracy: 0.7805\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8452 - val_loss: 0.5944 - val_accuracy: 0.7642\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8493 - val_loss: 0.5953 - val_accuracy: 0.7642\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8513 - val_loss: 0.5936 - val_accuracy: 0.7724\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8452 - val_loss: 0.5927 - val_accuracy: 0.7724\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8432 - val_loss: 0.5933 - val_accuracy: 0.7724\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8473 - val_loss: 0.5946 - val_accuracy: 0.7642\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8452 - val_loss: 0.5939 - val_accuracy: 0.7724\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8452 - val_loss: 0.5932 - val_accuracy: 0.7724\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8473 - val_loss: 0.5926 - val_accuracy: 0.7805\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8473 - val_loss: 0.5931 - val_accuracy: 0.7724\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8493 - val_loss: 0.5944 - val_accuracy: 0.7642\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8473 - val_loss: 0.5937 - val_accuracy: 0.7642\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8493 - val_loss: 0.5927 - val_accuracy: 0.7805\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.8473 - val_loss: 0.5962 - val_accuracy: 0.7561\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8473 - val_loss: 0.5943 - val_accuracy: 0.7642\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8473 - val_loss: 0.5948 - val_accuracy: 0.7724\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8473 - val_loss: 0.5943 - val_accuracy: 0.7724\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8452 - val_loss: 0.5951 - val_accuracy: 0.7724\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8452 - val_loss: 0.5939 - val_accuracy: 0.7724\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3828 - accuracy: 0.8493 - val_loss: 0.5929 - val_accuracy: 0.7805\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8432 - val_loss: 0.5951 - val_accuracy: 0.7561\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3821 - accuracy: 0.8452 - val_loss: 0.5932 - val_accuracy: 0.7724\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8452 - val_loss: 0.5941 - val_accuracy: 0.7642\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8473 - val_loss: 0.5927 - val_accuracy: 0.7805\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8473 - val_loss: 0.5925 - val_accuracy: 0.7805\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8473 - val_loss: 0.5962 - val_accuracy: 0.7642\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.8473 - val_loss: 0.5961 - val_accuracy: 0.7642\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8432 - val_loss: 0.5942 - val_accuracy: 0.7805\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8452 - val_loss: 0.5946 - val_accuracy: 0.7724\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3817 - accuracy: 0.8513 - val_loss: 0.5968 - val_accuracy: 0.7642\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8452 - val_loss: 0.5943 - val_accuracy: 0.7724\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8432 - val_loss: 0.5949 - val_accuracy: 0.7724\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8452 - val_loss: 0.5950 - val_accuracy: 0.7724\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8452 - val_loss: 0.5944 - val_accuracy: 0.7724\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8452 - val_loss: 0.5949 - val_accuracy: 0.7642\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8493 - val_loss: 0.5961 - val_accuracy: 0.7642\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3829 - accuracy: 0.8493 - val_loss: 0.5940 - val_accuracy: 0.7805\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8493 - val_loss: 0.5962 - val_accuracy: 0.7642\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8493 - val_loss: 0.5956 - val_accuracy: 0.7642\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8473 - val_loss: 0.5942 - val_accuracy: 0.7805\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8452 - val_loss: 0.5949 - val_accuracy: 0.7724\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8452 - val_loss: 0.5940 - val_accuracy: 0.7724\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8473 - val_loss: 0.5932 - val_accuracy: 0.7805\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8452 - val_loss: 0.5963 - val_accuracy: 0.7642\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.8452 - val_loss: 0.5979 - val_accuracy: 0.7561\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.8473 - val_loss: 0.5955 - val_accuracy: 0.7724\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8452 - val_loss: 0.5955 - val_accuracy: 0.7724\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8452 - val_loss: 0.5959 - val_accuracy: 0.7642\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8473 - val_loss: 0.5961 - val_accuracy: 0.7561\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8473 - val_loss: 0.5947 - val_accuracy: 0.7805\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3806 - accuracy: 0.8493 - val_loss: 0.5954 - val_accuracy: 0.7805\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8493 - val_loss: 0.5971 - val_accuracy: 0.7642\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8473 - val_loss: 0.5964 - val_accuracy: 0.7642\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3803 - accuracy: 0.8493 - val_loss: 0.5965 - val_accuracy: 0.7642\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8432 - val_loss: 0.5968 - val_accuracy: 0.7642\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8432 - val_loss: 0.5961 - val_accuracy: 0.7805\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.8452 - val_loss: 0.5989 - val_accuracy: 0.7642\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8473 - val_loss: 0.5997 - val_accuracy: 0.7561\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8432 - val_loss: 0.5957 - val_accuracy: 0.7724\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3806 - accuracy: 0.8452 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8452 - val_loss: 0.5975 - val_accuracy: 0.7724\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8473 - val_loss: 0.5968 - val_accuracy: 0.7724\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3803 - accuracy: 0.8452 - val_loss: 0.5974 - val_accuracy: 0.7642\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8432 - val_loss: 0.5988 - val_accuracy: 0.7642\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8473 - val_loss: 0.5976 - val_accuracy: 0.7805\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8411 - val_loss: 0.5963 - val_accuracy: 0.7805\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8452 - val_loss: 0.6014 - val_accuracy: 0.7561\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8473 - val_loss: 0.5994 - val_accuracy: 0.7642\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8411 - val_loss: 0.5972 - val_accuracy: 0.7805\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8432 - val_loss: 0.6008 - val_accuracy: 0.7561\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8473 - val_loss: 0.5977 - val_accuracy: 0.7642\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8432 - val_loss: 0.5975 - val_accuracy: 0.7724\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3798 - accuracy: 0.8473 - val_loss: 0.5979 - val_accuracy: 0.7642\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3797 - accuracy: 0.8452 - val_loss: 0.5984 - val_accuracy: 0.7724\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8493 - val_loss: 0.5988 - val_accuracy: 0.7642\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8493 - val_loss: 0.5962 - val_accuracy: 0.7805\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3795 - accuracy: 0.8452 - val_loss: 0.5977 - val_accuracy: 0.7724\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8493 - val_loss: 0.5987 - val_accuracy: 0.7642\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8452 - val_loss: 0.5959 - val_accuracy: 0.7805\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8432 - val_loss: 0.5967 - val_accuracy: 0.7805\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8473 - val_loss: 0.6006 - val_accuracy: 0.7561\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3797 - accuracy: 0.8493 - val_loss: 0.5976 - val_accuracy: 0.7724\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8452 - val_loss: 0.5973 - val_accuracy: 0.7724\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8432 - val_loss: 0.5964 - val_accuracy: 0.7805\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.8513 - val_loss: 0.5996 - val_accuracy: 0.7642\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8473 - val_loss: 0.5977 - val_accuracy: 0.7724\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8452 - val_loss: 0.5961 - val_accuracy: 0.7805\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8493 - val_loss: 0.6003 - val_accuracy: 0.7642\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8473 - val_loss: 0.5987 - val_accuracy: 0.7642\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8493 - val_loss: 0.5966 - val_accuracy: 0.7805\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8452 - val_loss: 0.5978 - val_accuracy: 0.7642\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3794 - accuracy: 0.8473 - val_loss: 0.5978 - val_accuracy: 0.7642\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.8493 - val_loss: 0.5975 - val_accuracy: 0.7642\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.8432 - val_loss: 0.5962 - val_accuracy: 0.7805\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3797 - accuracy: 0.8452 - val_loss: 0.5971 - val_accuracy: 0.7724\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8452 - val_loss: 0.5969 - val_accuracy: 0.7805\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8473 - val_loss: 0.6005 - val_accuracy: 0.7642\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8493 - val_loss: 0.5977 - val_accuracy: 0.7642\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8473 - val_loss: 0.6004 - val_accuracy: 0.7642\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3793 - accuracy: 0.8452 - val_loss: 0.5966 - val_accuracy: 0.7805\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8473 - val_loss: 0.5967 - val_accuracy: 0.7805\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3814 - accuracy: 0.8473 - val_loss: 0.5990 - val_accuracy: 0.7724\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8493 - val_loss: 0.5977 - val_accuracy: 0.7724\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.8452 - val_loss: 0.5969 - val_accuracy: 0.7805\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8493 - val_loss: 0.5983 - val_accuracy: 0.7642\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3796 - accuracy: 0.8473 - val_loss: 0.5981 - val_accuracy: 0.7642\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8513 - val_loss: 0.5966 - val_accuracy: 0.7724\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3793 - accuracy: 0.8493 - val_loss: 0.5979 - val_accuracy: 0.7724\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8513 - val_loss: 0.5985 - val_accuracy: 0.7724\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3793 - accuracy: 0.8493 - val_loss: 0.5983 - val_accuracy: 0.7724\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8473 - val_loss: 0.5982 - val_accuracy: 0.7724\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3798 - accuracy: 0.8493 - val_loss: 0.5984 - val_accuracy: 0.7724\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.8493 - val_loss: 0.6007 - val_accuracy: 0.7561\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3793 - accuracy: 0.8432 - val_loss: 0.5975 - val_accuracy: 0.7805\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8452 - val_loss: 0.5989 - val_accuracy: 0.7724\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8493 - val_loss: 0.6025 - val_accuracy: 0.7642\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3787 - accuracy: 0.8473 - val_loss: 0.5989 - val_accuracy: 0.7724\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.8452 - val_loss: 0.5974 - val_accuracy: 0.7805\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8473 - val_loss: 0.5996 - val_accuracy: 0.7724\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8473 - val_loss: 0.5990 - val_accuracy: 0.7642\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3784 - accuracy: 0.8432 - val_loss: 0.5987 - val_accuracy: 0.7724\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3787 - accuracy: 0.8473 - val_loss: 0.5988 - val_accuracy: 0.7724\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3795 - accuracy: 0.8452 - val_loss: 0.6013 - val_accuracy: 0.7642\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3791 - accuracy: 0.8452 - val_loss: 0.5973 - val_accuracy: 0.7805\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3791 - accuracy: 0.8452 - val_loss: 0.5974 - val_accuracy: 0.7805\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8493 - val_loss: 0.6017 - val_accuracy: 0.7642\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8473 - val_loss: 0.5988 - val_accuracy: 0.7724\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8432 - val_loss: 0.5990 - val_accuracy: 0.7724\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.8473 - val_loss: 0.6004 - val_accuracy: 0.7642\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8473 - val_loss: 0.5991 - val_accuracy: 0.7724\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.8473 - val_loss: 0.5998 - val_accuracy: 0.7724\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3794 - accuracy: 0.8473 - val_loss: 0.5987 - val_accuracy: 0.7724\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.8473 - val_loss: 0.6008 - val_accuracy: 0.7724\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.8473 - val_loss: 0.5988 - val_accuracy: 0.7724\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.8493 - val_loss: 0.5982 - val_accuracy: 0.7724\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3787 - accuracy: 0.8473 - val_loss: 0.5991 - val_accuracy: 0.7724\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.8452 - val_loss: 0.5987 - val_accuracy: 0.7724\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3791 - accuracy: 0.8493 - val_loss: 0.5998 - val_accuracy: 0.7724\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3792 - accuracy: 0.8493 - val_loss: 0.5993 - val_accuracy: 0.7724\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.8534 - val_loss: 0.6011 - val_accuracy: 0.7642\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8473 - val_loss: 0.5975 - val_accuracy: 0.7724\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.8473 - val_loss: 0.5972 - val_accuracy: 0.7724\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8452 - val_loss: 0.5986 - val_accuracy: 0.7724\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3795 - accuracy: 0.8452 - val_loss: 0.6017 - val_accuracy: 0.7642\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.8493 - val_loss: 0.5990 - val_accuracy: 0.7724\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3791 - accuracy: 0.8473 - val_loss: 0.5990 - val_accuracy: 0.7805\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3775 - accuracy: 0.8473 - val_loss: 0.6021 - val_accuracy: 0.7642\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8493 - val_loss: 0.6011 - val_accuracy: 0.7642\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8493 - val_loss: 0.5995 - val_accuracy: 0.7724\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.8493 - val_loss: 0.5999 - val_accuracy: 0.7724\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8493 - val_loss: 0.6012 - val_accuracy: 0.7642\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8493 - val_loss: 0.5997 - val_accuracy: 0.7724\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8473 - val_loss: 0.6008 - val_accuracy: 0.7642\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.8493 - val_loss: 0.5991 - val_accuracy: 0.7724\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8452 - val_loss: 0.5989 - val_accuracy: 0.7724\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3776 - accuracy: 0.8513 - val_loss: 0.6011 - val_accuracy: 0.7642\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8473 - val_loss: 0.5995 - val_accuracy: 0.7724\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8534 - val_loss: 0.6031 - val_accuracy: 0.7642\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3787 - accuracy: 0.8452 - val_loss: 0.5995 - val_accuracy: 0.7724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPk5h925hZHR"
      },
      "source": [
        "prediction=model.predict_classes(X_test)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrjqS9DSiLNp",
        "outputId": "80fe7f5e-9db6-411f-c1bc-7c6ddd0a49a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(y_test,prediction)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7723577235772358"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOc8kyQhiVVX",
        "outputId": "4cac8ee3-c3de-4a79-c712-3527404112d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnFvcbIhipxH",
        "outputId": "b6adfbef-47d4-4a24-b4e5-f6a54d36bdba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(model_history.history['accuracy'])\n",
        "plt.plot(model_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdNykVjWjJBo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}